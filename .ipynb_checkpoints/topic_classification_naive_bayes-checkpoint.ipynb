{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWAjdfIsTyhI"
   },
   "source": [
    "# Topic Classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0KwRzrQTyhL"
   },
   "source": [
    "# Intro\n",
    "---\n",
    "In this project, you'll work with text data from newsgroup posts on a variety of topics. You'll train classifiers to distinguish posts by topics inferred from the text. Whereas with digit classification, where each input is relatively **dense** (represented as a 28x28 matrix of pixels, many of which are non-zero), here each document is relatively **sparse** (represented as a **bag-of-words**). Only a few words of the total vocabulary are active in any given document. The assumption is that a label depends only on the count of words, not their order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QNNjknnZTyhN"
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orEWeRJaTyhO"
   },
   "source": [
    "Load the data, stripping out metadata so that only textual features will be used, and restricting documents to 4 specific topics. By default, newsgroups data is split into training and test sets, but here the test set gets further split into development and test sets.  (If you remove the categories argument from the fetch function calls, you'd get documents from all 20 topics.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5b9J-D5DTyhP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2034,)\n",
      "dev label shape: (676,)\n",
      "test label shape: (677,)\n",
      "labels names: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test  = fetch_20newsgroups(subset='test',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "\n",
    "num_test = int(len(newsgroups_test.target) / 2)\n",
    "test_data, test_labels   = newsgroups_test.data[num_test:], newsgroups_test.target[num_test:]\n",
    "dev_data, dev_labels     = newsgroups_test.data[:num_test], newsgroups_test.target[:num_test]\n",
    "train_data, train_labels = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "print('training label shape:', train_labels.shape)\n",
    "print('dev label shape:',      dev_labels.shape)\n",
    "print('test label shape:',     test_labels.shape)\n",
    "print('labels names:',         newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOS6IyT0TyhR"
   },
   "source": [
    "### Examining your data\n",
    "---\n",
    "\n",
    " 1. For each of the first 5 training examples, print the text of the message along with the label (checkout newsgroups_train.target_names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "LFFUipfaTyhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example 0 Label: comp.graphics\n",
      "Training Example 0 Message:\n",
      " Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "Training Example 1 Label: talk.religion.misc\n",
      "Training Example 1 Message:\n",
      " \n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "Training Example 2 Label: sci.space\n",
      "Training Example 2 Message:\n",
      " \n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "Training Example 3 Label: alt.atheism\n",
      "Training Example 3 Message:\n",
      " I have a request for those who would like to see Charley Wingate\n",
      "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
      "appear to be quite a few of you.)  \n",
      "\n",
      "It is clear that Mr. Wingate intends to continue to post tangential or\n",
      "unrelated articles while ingoring the Challenges themselves.  Between\n",
      "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
      "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
      "\n",
      "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
      "will just go away, and he is doing his level best to change the\n",
      "subject.  Given that this seems a rather common net.theist tactic, I\n",
      "would like to suggest that we impress upon him our desire for answers,\n",
      "in the following manner:\n",
      "\n",
      "1. Ignore any future articles by Mr. Wingate that do not address the\n",
      "Challenges, until he answers them or explictly announces that he\n",
      "refuses to do so.\n",
      "\n",
      "--or--\n",
      "\n",
      "2. If you must respond to one of his articles, include within it\n",
      "something similar to the following:\n",
      "\n",
      "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
      "\n",
      "Really, I'm not looking to humiliate anyone here, I just want some\n",
      "honest answers.  You wouldn't think that honesty would be too much to\n",
      "ask from a devout Christian, would you?  \n",
      "\n",
      "Nevermind, that was a rhetorical question.\n",
      "Training Example 4 Label: sci.space\n",
      "Training Example 4 Message:\n",
      " AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?\n"
     ]
    }
   ],
   "source": [
    "def Q1(num_examples=5):\n",
    "    ### STUDENT START ###\n",
    "    for i in range(num_examples):\n",
    "        #pull the label at the ith index, this will show up as an integer value\n",
    "        ind = train_labels[i]\n",
    "        #print the name of the label using target_names\n",
    "        print(\"Training Example\", i, \"Label:\", newsgroups_train.target_names[ind])\n",
    "        #print the content of the data at the ith index\n",
    "        print(\"Training Example\", i, \"Message:\\n\", newsgroups_train.data[i])\n",
    "    ### STUDENT END ###\n",
    "Q1(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r53zpu-mTyhU"
   },
   "source": [
    "### Text representation\n",
    "---\n",
    "\n",
    "1. Transform the training data into a matrix of **word** unigram feature vectors.\n",
    "  1. What is the size of the vocabulary? \n",
    "  1. What is the average number of non-zero features per example?  \n",
    "  1. What is the fraction of the non-zero entries in the matrix?  \n",
    "  1. What are the 0th and last feature strings (in alphabetical order)?\n",
    "  - _Use `CountVectorization` and its `.fit_transform` method.  Use `.nnz` and `.shape` attributes, and `.get_feature_names` method._\n",
    "1. Now transform the training data into a matrix of **word** unigram feature vectors restricting to the vocabulary with these 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"].  Confirm the size of the vocabulary. \n",
    "  1. What is the average number of non-zero features per example?\n",
    "  - _Use `CountVectorization(vocabulary=...)` and its `.transform` method._\n",
    "1. Now transform the training data into a matrix of **character** bigram and trigram feature vectors.  \n",
    "  1. What is the size of the vocabulary?\n",
    "  - _Use `CountVectorization(analyzer=..., ngram_range=...)` and its `.fit_transform` method._\n",
    "1. Now transform the training data into a matrix of **word** unigram feature vectors and prune words that appear in fewer than 10 documents.  \n",
    "  1. What is the size of the vocabulary?<br/>\n",
    "  - _Use `CountVectorization(min_df=...)` and its `.fit_transform` method._\n",
    "1. Now again transform the training data into a matrix of **word** unigram feature vectors. \n",
    " 1. What is the fraction of words in the development vocabulary that is missing from the training vocabulary?\n",
    " - _Hint: Build vocabularies for both train and dev and look at the size of the difference._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_xkWZwBVTyhV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Part 1...\n",
      "The size of the vocabulary is 26879\n",
      "Average number of non-zero features per example: 96.705998\n",
      "Fraction of the non-zero entries in the matrix: 0.0036\n",
      "The 0th feature string is: 00\n",
      "The last feature string is: zyxel\n",
      "For Part 2...\n",
      "The size of the vocabulary is 4\n",
      "Average number of non-zero features per example: 0.268437\n",
      "For Part 3...\n",
      "The size of the vocabulary is 35478\n",
      "For Part 4...\n",
      "The size of the vocabulary is 3064\n",
      "For Part 5...\n",
      "Training data vocabulary size: 26879\n",
      "Dev data vocabulary size: 16246\n",
      "Fraction of words in the dev vocab that's missing from training vocab is 0.25\n"
     ]
    }
   ],
   "source": [
    "def Q2():\n",
    "    ### STUDENT START ###\n",
    "    #Part 1 - Transform the training data into a matrix of word unigram feature vectors\n",
    "    vectorizer = CountVectorizer()\n",
    "    P1 = vectorizer.fit_transform(train_data)\n",
    "    print(\"For Part 1...\")\n",
    "    #1A: Get vocabulary using the shape attribute\n",
    "    print(\"The size of the vocabulary is\", P1.shape[1])\n",
    "    #1B: Average number of non-zero features per example \n",
    "    P1_nnz_ex = [P1[i].nnz for i in range(P1.shape[0])]\n",
    "    P1_fin_av = round(sum(P1_nnz_ex) / len(P1_nnz_ex),6)\n",
    "    #1C: fraction of the non-zero entries in the matrix\n",
    "    frac_mat = round(P1.nnz/(P1.shape[0]*P1.shape[1]), 4) \n",
    "    #print out answers\n",
    "    print(\"Average number of non-zero features per example:\", P1_fin_av)\n",
    "    print(\"Fraction of the non-zero entries in the matrix:\", frac_mat)\n",
    "    #get_feature_names() is already alphabetized, so just pull 0th and -1th index\n",
    "    print(\"The 0th feature string is:\", vectorizer.get_feature_names()[0])\n",
    "    print(\"The last feature string is:\", vectorizer.get_feature_names()[-1])\n",
    "    \n",
    "    #Part 2 - restrict the vocab\n",
    "    print(\"For Part 2...\")\n",
    "    vectorizer = CountVectorizer(vocabulary = [\"atheism\", \"graphics\", \"space\", \"religion\"])\n",
    "    P2 = vectorizer.transform(train_data)\n",
    "    #Confirm the vocabulary size from shape attribute\n",
    "    print(\"The size of the vocabulary is\", P2.shape[1])\n",
    "    #2A - Average number of non-zero features per example\n",
    "    P2_nnz_ex = [P2[i].nnz for i in range(P2.shape[0])]\n",
    "    P2_fin_av = round(sum(P2_nnz_ex) / len(P2_nnz_ex),6)\n",
    "    print(\"Average number of non-zero features per example:\", P2_fin_av)\n",
    "    \n",
    "    #Part 3 - character bigram and trigram feature vectors\n",
    "    print(\"For Part 3...\")\n",
    "    vectorizer = CountVectorizer(analyzer = 'char', ngram_range=(2,3))\n",
    "    P3 = vectorizer.fit_transform(train_data)\n",
    "    #3A: Get vocabulary using the shape attribute\n",
    "    print(\"The size of the vocabulary is\", P3.shape[1])\n",
    "    \n",
    "    #Part 4 - prune words that appear in fewer than 10 documents\n",
    "    print(\"For Part 4...\")\n",
    "    vectorizer = CountVectorizer(min_df = 10)\n",
    "    P4 = vectorizer.fit_transform(train_data)\n",
    "    #4A: Get vocabulary using the shape attribute\n",
    "    print(\"The size of the vocabulary is\", P4.shape[1])\n",
    "    \n",
    "    #Part 5 - Build vocabularies for both train and dev and look at the size of the difference\n",
    "    print(\"For Part 5...\")\n",
    "    P5_vectorizer = CountVectorizer()\n",
    "    P5_train = P5_vectorizer.fit_transform(train_data)\n",
    "    train_vocab = list(P5_vectorizer.vocabulary_.keys())\n",
    "    P5_dev = P5_vectorizer.fit_transform(dev_data)\n",
    "    dev_vocab = list(P5_vectorizer.vocabulary_.keys())\n",
    "    print(\"Training data vocabulary size:\", P5_train.shape[1])\n",
    "    print(\"Dev data vocabulary size:\", P5_dev.shape[1])\n",
    "    # num words in dev that are not in train / total number of words in dev\n",
    "    not_in_train = [w for w in dev_vocab if w not in train_vocab]\n",
    "    ans = len(not_in_train) / len(dev_vocab)\n",
    "    print(\"Fraction of words in the dev vocab that's missing from training vocab is\", round(ans,2))\n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaSTL9OTyhX"
   },
   "source": [
    "### Initial model evaluation\n",
    "---\n",
    "\n",
    "1. Transform the training and development data to matrices of word unigram feature vectors.\n",
    "1. Produce several k-Nearest Neigbors models by varying k, including one with k set to optimize f1 score.  For each model, show the k value and f1 score. \n",
    "1. Produce several Naive Bayes models by varying smoothing (alpha), including one with alpha set approximately to optimize f1 score.  For each model, show the alpha value and f1 score.\n",
    "1. Produce several Logistic Regression models by varying L2 regularization strength (C), including one with C set approximately to optimize f1 score.  For each model, show the C value, f1 score, and sum of squared weights for each topic.\n",
    "1. Why doesn't k-Nearest Neighbors work well for this problem?\n",
    "1. Why doesn't Logistic Regression work as well as Naive Bayes does?\n",
    "1. What is the relationship between logistic regression's sum of squared weights vs. C value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g9JvhGBRTyhX",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k = 1, the F1 score is 0.3805\n",
      "When k = 2, the F1 score is 0.3805\n",
      "When k = 3, the F1 score is 0.4084\n",
      "When k = 4, the F1 score is 0.4031\n",
      "When k = 7, the F1 score is 0.4505\n",
      "When k = 9, the F1 score is 0.4366\n",
      "When k = 12, the F1 score is 0.4211\n",
      "When k = 15, the F1 score is 0.4326\n",
      "When k = 25, the F1 score is 0.4161\n",
      "When alpha = 1e-10, the F1 score is 0.7472\n",
      "When alpha = 0.001, the F1 score is 0.7703\n",
      "When alpha = 0.1, the F1 score is 0.7903\n",
      "When alpha = 0.5, the F1 score is 0.7863\n",
      "When alpha = 1.0, the F1 score is 0.7777\n",
      "When alpha = 2.0, the F1 score is 0.7690\n",
      "When alpha = 10.0, the F1 score is 0.6675\n",
      "When C = 0.01:\n",
      " F1 score is 0.6647\n",
      "Sum of squared weights is [2.541478743984131, 2.939709368361363, 2.862467836458274, 2.2497877552920813]\n",
      "When C = 0.05:\n",
      " F1 score is 0.6867\n",
      "Sum of squared weights is [14.073967727717658, 13.668380010357769, 14.604297323772386, 11.860677350612479]\n",
      "When C = 0.1:\n",
      " F1 score is 0.6966\n",
      "Sum of squared weights is [27.13220960993868, 24.667992353486742, 27.458105086463757, 23.025488889045373]\n",
      "When C = 0.2:\n",
      " F1 score is 0.7059\n",
      "Sum of squared weights is [49.745672386104665, 42.74541491924734, 49.32731559278821, 42.67680630862567]\n",
      "When C = 0.3:\n",
      " F1 score is 0.7101\n",
      "Sum of squared weights is [69.26855844073438, 57.86311092067688, 67.90641701634017, 59.76464409928311]\n",
      "When C = 0.5:\n",
      " F1 score is 0.7101\n",
      "Sum of squared weights is [102.60878381618774, 83.10179019482264, 99.01673524919029, 89.0024842201507]\n",
      "When C = 1:\n",
      " F1 score is 0.6944\n",
      "Sum of squared weights is [166.95392139612844, 130.92462659820725, 158.0533236401661, 145.75169520738368]\n",
      "When C = 2:\n",
      " F1 score is 0.6925\n",
      "Sum of squared weights is [257.5855715164318, 197.97263040427728, 239.9022563722656, 226.63841155419672]\n",
      "When C = 5:\n",
      " F1 score is 0.6909\n",
      "Sum of squared weights is [423.0918691137375, 322.42420968127624, 389.70971649504247, 378.06760092330705]\n",
      "When C = 10:\n",
      " F1 score is 0.6852\n",
      "Sum of squared weights is [585.9310434331726, 448.27915140089135, 539.0383362324185, 531.1431577589268]\n"
     ]
    }
   ],
   "source": [
    "def Q3():\n",
    "    ### STUDENT START ###\n",
    "    vectorizer = CountVectorizer()\n",
    "    new_train = vectorizer.fit_transform(train_data)\n",
    "    new_dev = vectorizer.transform(dev_data)\n",
    "    \n",
    "    #KNN models\n",
    "    k_values = [1,2,3,4,7,9,12,15,25]\n",
    "    for i in k_values:\n",
    "        #create KNN model with k = 1\n",
    "        knn = KNeighborsClassifier(n_neighbors = i)\n",
    "        #train the model on the mini training data provided\n",
    "        knn.fit(new_train, train_labels)\n",
    "        knn_pred = knn.predict(new_dev)\n",
    "        knn_f1 = metrics.f1_score(dev_labels, knn_pred, average = \"weighted\")\n",
    "        print(\"When k = {}, the F1 score is {:.4f}\".format(i, knn_f1))\n",
    "    \n",
    "    #Naive Bayes models\n",
    "    alphas = [1.0e-10, 0.001, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "    for a in alphas:\n",
    "        nb = MultinomialNB(alpha = a)\n",
    "        nb.fit(new_train, train_labels)\n",
    "        nb_pred = nb.predict(new_dev)\n",
    "        nb_f1 = metrics.f1_score(dev_labels, nb_pred, average = \"weighted\")\n",
    "        print(\"When alpha = {}, the F1 score is {:.4f}\".format(a, nb_f1))\n",
    "    \n",
    "    #Logistic Regression Models\n",
    "    c_vals = [.01, 0.05, .1, .2, .3, .5, 1, 2, 5, 10]\n",
    "    for c in c_vals:\n",
    "        lr = LogisticRegression(C = c, solver = \"liblinear\", multi_class = \"auto\")\n",
    "        #fit and pred on vectorized train and dev data\n",
    "        lr.fit(new_train, train_labels)\n",
    "        lr_pred = lr.predict(new_dev)\n",
    "        lr_f1 = metrics.f1_score(dev_labels, lr_pred, average = \"weighted\")\n",
    "        ssw = []\n",
    "        #loop through all weights to calculate the sum of squared weights\n",
    "        for i in range(lr.coef_.shape[0]):\n",
    "            squ = [x ** 2 for x in lr.coef_[i]]\n",
    "            ssw.append(sum(squ))\n",
    "        print(\"When C = {}:\\n F1 score is {:.4f}\".format(c,lr_f1))\n",
    "        print(\"Sum of squared weights is\", ssw)\n",
    "    \n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K9kU5AETyhY"
   },
   "source": [
    "KNN models are very susceptible to overfitting due to the curse of dimensionality. This phenomenon occurs for this application because the feature space becomes increasingly sparse for an increasing number of dimensions of a fixed-size training dataset. Because of this, even the closest neighbors are too far away in a high-dimensional space to give a good estimate.\n",
    "\n",
    "Naive Bayes is more successful than Logistic Regression for this text classification application likely due to the sample size. We know that as training size reaches infinity, the logistic regression model performs better than the Naive Bayes model. Naive Bayes also assumes that each of the features (the words in the document) are conditionally independent, this gives the Naive Bayes model a higher bias but lower variance compared to logistic regression. The dataset in this case follows that bias, so it produces a better classifier.\n",
    "\n",
    "As C increase, so do the sum of squared weights, because both are inversely related to the regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b46HltEPTyhY"
   },
   "source": [
    "### Feature exploration\n",
    "---\n",
    "\n",
    "1. Transform the data to a matrix of word **bigram** feature vectors.  Produce a Logistic Regression model.\n",
    "1. For each topic, find the 5 features with the largest weights (not absolute value). If there are no overlaps, you can expect 20 features in total.\n",
    "1. Show a 20 row (features) x 4 column (topics) table of the weights. So, for each of the features (words) found, we show their weight for all topics.\n",
    "1. Do you see any surprising features in this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DerfvONsTyha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features for the topic alt.atheism:\n",
      "['are you', 'you are', 'was just', 'cheers kent', 'claim that']\n",
      "Top 5 features for the topic comp.graphics:\n",
      "['is there', 'out there', 'comp graphics', 'in advance', 'looking for']\n",
      "Top 5 features for the topic sci.space:\n",
      "['it was', 'and such', 'sci space', 'the moon', 'the space']\n",
      "Top 5 features for the topic talk.religion.misc:\n",
      "['of jesus', 'but he', 'ignorance is', 'cheers kent', 'the fbi']\n",
      "               alt.atheism  comp.graphics  sci.space  talk.religion.misc\n",
      "are you           0.446954      -0.248265  -0.097153           -0.305622\n",
      "you are           0.472741      -0.279893  -0.481327            0.028378\n",
      "was just          0.482050      -0.131429  -0.128921           -0.227467\n",
      "cheers kent       0.555719      -0.697906  -0.663762            0.534808\n",
      "claim that        0.605549      -0.199053  -0.274361           -0.140364\n",
      "is there         -0.340882       0.754979  -0.468275           -0.257080\n",
      "out there        -0.274802       0.758674  -0.479056           -0.277087\n",
      "comp graphics    -0.292166       0.801226  -0.371006           -0.285186\n",
      "in advance       -0.459351       0.832564  -0.438493           -0.418455\n",
      "looking for      -0.630341       1.108352  -0.499898           -0.571866\n",
      "it was           -0.203029      -0.309681   0.525396           -0.313552\n",
      "and such         -0.204269      -0.337506   0.590496           -0.218202\n",
      "sci space        -0.258008      -0.329182   0.621072           -0.221246\n",
      "the moon         -0.350563      -0.492736   0.830998           -0.213800\n",
      "the space        -0.268187      -0.530119   0.871114           -0.273843\n",
      "of jesus         -0.091910      -0.173768  -0.212390            0.423754\n",
      "but he           -0.190019      -0.216878  -0.137374            0.491875\n",
      "ignorance is     -0.158011      -0.171073  -0.139574            0.504305\n",
      "cheers kent       0.555719      -0.697906  -0.663762            0.534808\n",
      "the fbi          -0.131974      -0.211356  -0.295288            0.551991\n"
     ]
    }
   ],
   "source": [
    "def Q4():\n",
    "    ### STUDENT START ###\n",
    "    #transform the data into bigram feature vectors using the analyzer and ngram_range parameters\n",
    "    vectorizer = CountVectorizer(analyzer = 'word', ngram_range=(2,2))\n",
    "    new_train = vectorizer.fit_transform(train_data)\n",
    "    #pull in the vocabulary \n",
    "    vocab = vectorizer.get_feature_names()\n",
    "\n",
    "    #create LR model using the provided arguments\n",
    "    lr = LogisticRegression(C=0.5, solver=\"liblinear\", multi_class=\"auto\")\n",
    "    lr.fit(new_train, train_labels)\n",
    "\n",
    "    #create empty index list of 20 zeroes\n",
    "    indices = np.zeros(20, dtype=int)\n",
    "    for i in range(len(newsgroups_train.target_names)):\n",
    "        #pull the coefs for each label and sort them using argsort, pull top 5 \n",
    "        topic_coefs = np.array(lr.coef_[i])\n",
    "        coef_sort = np.argsort(topic_coefs)\n",
    "        top_5 = coef_sort[-5:]\n",
    "        #save these five indices into the empty list\n",
    "        indices[i*5:(i+1)*5] = top_5\n",
    "        print(\"Top 5 features for the topic {}:\".format(newsgroups_train.target_names[i]))\n",
    "        features = []\n",
    "        #pull the vocab words from vocab with the corresponding index\n",
    "        features = [vocab[i] for i in top_5]\n",
    "        print(features)\n",
    "    \n",
    "    #create new list of the vocab words and create a dataframe using the bigrams as the index column\n",
    "    all_20_ft = [vocab[i] for i in indices]\n",
    "    df = pd.DataFrame(index = all_20_ft)\n",
    "    \n",
    "    #add column to dataframe for the weights for each category\n",
    "    for i in range(len(newsgroups_train.target_names)):\n",
    "        colname = newsgroups_train.target_names[i]\n",
    "        df[colname]=lr.coef_[i,indices]\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odPhAx_yTyhb"
   },
   "source": [
    "Answer: A couple of the bigrams seem interesting to me. For starters, \"the FBI\" having a high weight for the topic of religion. Also, \"cheers kent\" appears twice, having high weights for the topics of atheism *and* religion. I did some research and apparently Kent Hovind is a prominent christian evangelist, so it makes sense that his name is referenced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNC3BCjUTyhb"
   },
   "source": [
    "### Pre-processing for text\n",
    "---\n",
    "\n",
    "To improve generalization, it is common to try preprocessing text in various ways before splitting into words. For example, you could try transforming strings to lower case, replacing sequences of numbers with single tokens, removing various non-letter characters, and shortening long words.\n",
    "\n",
    "1. Produce a Logistic Regression model (with no preprocessing of text). **Note that you may need to override the \"default\" preprocessing with an identity function**. Evaluate and show its f1 score and size of the dictionary.\n",
    "1. Produce an improved Logistic Regression model by preprocessing the text. Evaluate and show its f1 score and size of the vocabulary.  Aim for an improvement in f1 score of 0.02. **Note: this is actually very hard**.\n",
    "1. How much did the improved model reduce the vocabulary size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexandradrossos/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1_preprocessor(doc):\n",
    "    return(doc)\n",
    "\n",
    "def my_test(doc):\n",
    "    return None\n",
    "\n",
    "#credit to: https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a\n",
    "def my_preprocessor(doc):\n",
    "    #lower all the words\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    #remove all the stop wods in the nltk corpus\n",
    "    sw_nltk = stopwords.words('english')\n",
    "    words = [word for word in doc.split() if word.lower() not in sw_nltk]\n",
    "    doc = \" \".join(words)\n",
    "    \n",
    "    #replace numbers with just 'num'\n",
    "    doc = re.sub('\\d+', 'num', doc)\n",
    "    doc = re.sub('[^(a-zNUM)]', ' ', doc)\n",
    "    \n",
    "    #replace all the contractions with their expanded meanings\n",
    "    contractions = [\"could've\", \"would've\", \"should've\", \"hasn't\", \"wasn't\", \"aren't\", \"'s\", \"didn't\"]\n",
    "    subs = [\"could have\", \"would have\", \"should have\", \"has not\", \"was not\", \"are not\", \" is \", \"did not\"]\n",
    "    for i in range(len(contractions)):\n",
    "        doc = re.sub(contractions[i], subs[i], doc)\n",
    "    doc = ' '.join([x[:5] for x in doc.split()])\n",
    "    \n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3lDatbSPTyhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using no preprocessing, the logistic regression model returned:\n",
      "F1 score: 0.7069\n",
      "Vocabulary size: 33291\n",
      "Using custom preprocessing, the improved logistic regression model returned:\n",
      "F1 score: 0.7292\n",
      "Vocabulary size: 15036\n",
      "Pre-processing improved the model by 0.0223\n",
      "The improved model reduced the vocabulary size by 18255 words\n"
     ]
    }
   ],
   "source": [
    "def Q5():\n",
    "    ### STUDENT START ###\n",
    "    #create vectorizer using the identity function pre processor function\n",
    "    p1_vectorizer = CountVectorizer(preprocessor = p1_preprocessor)\n",
    "    #create training, dev, and pull vocab\n",
    "    p1_new_train = p1_vectorizer.fit_transform(train_data)\n",
    "    p1_new_dev = p1_vectorizer.transform(dev_data)\n",
    "    p1_vocab = p1_vectorizer.get_feature_names()\n",
    "    \n",
    "    #create LR model with provided parameters, fit it, predict, and calculate f1 score\n",
    "    lr = LogisticRegression(C = 0.5, solver = \"liblinear\", multi_class = \"auto\")\n",
    "    lr.fit(p1_new_train, train_labels)\n",
    "    lr_pred = lr.predict(p1_new_dev)\n",
    "    lr_f1 = metrics.f1_score(dev_labels, lr_pred, average = \"weighted\")\n",
    "    print(\"Using no preprocessing, the logistic regression model returned:\")\n",
    "    print(\"F1 score: {:.4f}\".format(lr_f1))\n",
    "    print(\"Vocabulary size: {}\".format(len(p1_vocab)))\n",
    "    \n",
    "    #create improved logistic regression model with custom pre processor function\n",
    "    p2_vectorizer = CountVectorizer(preprocessor = my_preprocessor)\n",
    "    p2_new_train = p2_vectorizer.fit_transform(train_data)\n",
    "    p2_new_dev = p2_vectorizer.transform(dev_data)\n",
    "    p2_vocab = p2_vectorizer.get_feature_names()\n",
    "    \n",
    "    #calculate improved f1 score\n",
    "    lr_2 = LogisticRegression(C = 0.5, solver = \"liblinear\", multi_class = \"auto\")\n",
    "    lr_2.fit(p2_new_train, train_labels)\n",
    "    lr_2_pred = lr_2.predict(p2_new_dev)\n",
    "    lr_2_f1 = metrics.f1_score(dev_labels, lr_2_pred, average = \"weighted\")\n",
    "    f1_improve = lr_2_f1 - lr_f1\n",
    "    #print answers\n",
    "    print(\"Using custom preprocessing, the improved logistic regression model returned:\")\n",
    "    print(\"F1 score: {:.4f}\".format(lr_2_f1))\n",
    "    print(\"Vocabulary size: {}\".format(len(p2_vocab)))\n",
    "    print(\"Pre-processing improved the model by {}\".format(round(f1_improve, 4)))\n",
    "    print(\"The improved model reduced the vocabulary size by {} words\".format(len(p1_vocab) - len(p2_vocab)))\n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLRc7vDBTyhb"
   },
   "source": [
    "### L1 and L2 regularization\n",
    "---\n",
    "\n",
    "The idea of regularization is to avoid learning very large weights (which are likely to fit the training data, but not generalize well) by adding a penalty to the total size of the learned weights. Logistic regression seeks the set of weights that minimizes errors in the training data AND has a small total size. The default L2 regularization computes this size as the sum of the squared weights (as in Part 3 above). L1 regularization computes this size as the sum of the absolute values of the weights. Whereas L2 regularization makes all the weights relatively small, **L1 regularization drives many of the weights to 0, effectively removing unimportant features**. For this reason, we can use it as a way to do \"feature selection\".\n",
    "\n",
    "1. For several L1 regularization strengths ...\n",
    "  1. Produce a Logistic Regression model using the **L1** regularization strength.  Reduce the vocabulary to only those features that have at least one non-zero weight among the four categories.\n",
    "  1. Produce a new Logistic Regression model using the reduced vocabulary . For this new model, use an **L2** regularization strength of 0.5.  \n",
    "  1. Evaluate and show the L1 regularization strength, vocabulary size, and f1 score associated with the new model.\n",
    "1. Show a plot of f1 score vs. log vocabulary size.  Each point corresponds to a specific L1 regularization strength used to reduce the vocabulary.\n",
    "1. How does performance of the models based on reduced vocabularies compare to that of a model based on the full vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7dva_PsvTyhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Full_Vocab_F1  Reduced_Vocab_Size  Reduced_Vocab_F1  Log_vocab\n",
      "0.01          0.422986                  17            0.4678   2.833213\n",
      "0.05          0.586772                 125            0.6403   4.828314\n",
      "0.10          0.642458                 211            0.6925   5.351858\n",
      "0.20          0.696025                 383            0.6697   5.948035\n",
      "0.30          0.692867                 538            0.6702   6.287859\n",
      "0.50          0.683432                 789            0.6706   6.670766\n",
      "1.00          0.696291                1090            0.6913   6.993933\n",
      "2.00          0.694018                1746            0.6853   7.465083\n",
      "5.00          0.681363                2690            0.7012   7.897296\n",
      "10.00         0.658163                3401            0.6927   8.131825\n",
      "20.00         0.653787                4112            0.6935   8.321665\n",
      "50.00         0.644203                6072            0.6887   8.711443\n",
      "100.00        0.620856                7711            0.6951   8.950403\n",
      "200.00        0.632277               14039            0.7012   9.549594\n",
      "500.00        0.589776               22607            0.7043  10.026015\n",
      "1000.00       0.607016               25508            0.6839  10.146747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Q6():\n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    np.random.seed(0)\n",
    "\n",
    "    ### STUDENT START ###\n",
    "    #vectorize train and dev data and pull the original vocabulary \n",
    "    vectorizer = CountVectorizer()\n",
    "    new_train = vectorizer.fit_transform(train_data)\n",
    "    new_dev = vectorizer.transform(dev_data)\n",
    "    og_vocab = np.array(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    #try various L1 regularization strengths\n",
    "    c_vals = [.01, 0.05, .1, .2, .3, .5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "    #create dictionary to eventually become a dataframe\n",
    "    d={'Full_Vocab_F1':[],'Reduced_Vocab_Size':[],'Reduced_Vocab_F1':[]}\n",
    "    for c in c_vals:\n",
    "        #create and fit LR model with provided parameters\n",
    "        lr = LogisticRegression(C = c, solver = \"liblinear\", tol=.015, penalty=\"l1\")\n",
    "        lr.fit(new_train, train_labels)\n",
    "        lr_pred = lr.predict(new_dev)\n",
    "        #get accuracy of model with full vocabulary\n",
    "        full_vocab_score = metrics.f1_score(dev_labels, lr_pred, average = \"weighted\")\n",
    "        d['Full_Vocab_F1'].append(full_vocab_score)\n",
    "        #get the indices where the coef_ is not 0\n",
    "        non_zeros = np.sum(lr.coef_ != 0, axis = 0) != 0\n",
    "        #reduce the vocab to be just the words with non-zero weights\n",
    "        new_vocab=og_vocab[non_zeros]\n",
    "        #pull length of the new vocabulary and add it to the vocab_size column\n",
    "        d['Reduced_Vocab_Size'].append(len(new_vocab))\n",
    "        \n",
    "        #vectorize data with the updated vocabulary\n",
    "        l2_vectorizer = CountVectorizer(vocabulary = new_vocab)\n",
    "        l2_new_train = l2_vectorizer.fit_transform(train_data)\n",
    "        l2_new_dev = l2_vectorizer.transform(dev_data)\n",
    "        \n",
    "        #get the f1 score of the new model \n",
    "        lr_2 = LogisticRegression(C = 0.5, solver = \"liblinear\", tol=.015, penalty=\"l2\") \n",
    "        lr_2.fit(l2_new_train, train_labels)\n",
    "        lr_2_pred = lr_2.predict(l2_new_dev)\n",
    "        lr_2_f1 = metrics.f1_score(dev_labels, lr_2_pred, average = \"weighted\")\n",
    "        d['Reduced_Vocab_F1'].append(round(lr_2_f1,4))\n",
    "    #create dataframe from dictionary and set index to be the L1 Regularization strengths   \n",
    "    df = pd.DataFrame(d, index = c_vals)\n",
    "    #take the log of the vocabulary size for the graph\n",
    "    df[\"Log_vocab\"] = np.log(df[\"Reduced_Vocab_Size\"])\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    #plot f1 score vs. log of vocab size\n",
    "    plt.plot(df[\"Log_vocab\"], df[\"Reduced_Vocab_F1\"],\n",
    "            color='red')\n",
    "    plt.xlabel('Log of model vocabulary size')\n",
    "    plt.ylabel('Model F1 score')\n",
    "    plt.title('f1 score vs. log vocabulary siz')\n",
    "    plt.show()\n",
    "        \n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbrmPrLaTyhc"
   },
   "source": [
    "ANSWER: Comparing the F1 scores of the models using the full vocabulary vs. the \"feature selected\" reduced vocabulary, we can see that reducing the vocabulary by removing the words with zero weights improves the F1 scores for each L1 regularization strength that we tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQJQimS8Tyhd"
   },
   "source": [
    "### TfIdf\n",
    "---\n",
    "As you may recall [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) stands for *term frequency inverse document frequency* and is a way to assign a weight to each word or token signifying their importance for a document in a corpus (a collection of documents).\n",
    "\n",
    "Produce a Logistic Regression model based on data represented in tf-idf form, with L2 regularization strength of 100.  Evaluate and show the f1 score.  How is `TfidfVectorizer` different than `CountVectorizer`?\n",
    "\n",
    "1. How is `TfidfVectorizer` different than `CountVectorizer`?\n",
    "1. Show the 3 documents with highest R ratio, where ...\n",
    "  - $R\\,ratio = maximum\\,predicted\\,probability \\div predicted\\,probability\\,of\\,correct\\,label$\n",
    "1. Explain what the R ratio describes.\n",
    "1. What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Llsrh11LTyhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Logistic Regression Model using Tfidf Vectorizer: 0.7598\n",
      "R ratio: 287.1792\n",
      "Predicted Label: talk.religion.misc\n",
      "True Label: alt.atheism\n",
      "Document: \n",
      "The 24 children were, of course, killed by a lone gunman in a second story\n",
      "window, who fired eight bullets in the space of two seconds...\n",
      " \n",
      "\n",
      "R ratio: 325.0040\n",
      "Predicted Label: comp.graphics\n",
      "True Label: talk.religion.misc\n",
      "Document: Can anyone provide me a ftp site where I can obtain a online version\n",
      "of the Book of Mormon. Please email the internet address if possible. \n",
      "\n",
      "R ratio: 929.3573\n",
      "Predicted Label: comp.graphics\n",
      "True Label: talk.religion.misc\n",
      "Document: I am pleased to announce that a *revised version* of _The Easy-to-Read Book\n",
      "of Mormon_ (former title: _Mormon's Book_) by Lynn Matthews Anderson is now\n",
      "available through anonymous ftp (see information below). In addition to the\n",
      "change in title, the revised ETR BOM has been shortened by several pages\n",
      "(eliminating many extraneous \"that's\" and \"of's\"), and many (minor) errors\n",
      "have been corrected. This release includes a simplified Joseph Smith Story,\n",
      "testimonies of the three and eight witnesses, and a \"Words-to-Know\"\n",
      "glossary.\n",
      "\n",
      "As with the previous announcement, readers are reminded that this is a\n",
      "not-for-profit endeavor. This is a copyrighted work, but people are welcome\n",
      "to make *verbatim* copies for personal use. People can recuperate the\n",
      "actual costs of printing (paper, copy center charges), but may not charge\n",
      "anything for their time in making copies, or in any way realize a profit\n",
      "from the use of this book. See the permissions notice in the book itself\n",
      "for the precise terms.\n",
      "\n",
      "Negotiations are currently underway with a Mormon publisher vis-a-vis the\n",
      "printing and distribution of bound books. (Sorry, I'm out of the wire-bound\n",
      "\"first editions.\") I will make another announcement about the availability\n",
      "of printed copies once everything has been worked out.\n",
      "\n",
      "FTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\n",
      "pub\" (you won't see anything at all until you do).\n",
      "\n",
      "\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\n",
      "RTF (rich text format). (ASCII, LaTeX, and other versions can be made\n",
      "available; contact dba@andrew.cmu.edu for details.) You should be able to\n",
      "print the postscript file on any postscript printer (such as an Apple\n",
      "Laserwriter); let dba know if you have any difficulties. (The postscript in\n",
      "the last release had problems on some printers; this time it should work\n",
      "better.) RTF is a standard document interchange format that can be read in\n",
      "by a number of word processors, including Microsoft Word for both the\n",
      "Macintosh and Windows. If you don't have a postscript printer, you may be\n",
      "able to use the RTF file to print out a copy of the book.\n",
      "\n",
      "-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\n",
      "-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\n",
      "\n",
      "For more information about how this project came about, please refer to my\n",
      "article in the current issue of _Sunstone_, entitled \"Delighting in\n",
      "Plainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\n",
      "\n",
      "Send all inquiries and comments to:\n",
      "\n",
      "    Lynn Matthews Anderson\n",
      "    5806 Hampton Street\n",
      "    Pittsburgh, PA 15206 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Q7():\n",
    "    ### STUDENT START ###\n",
    "    #vectorize the train and dev data using the TFIDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    new_train = vectorizer.fit_transform(train_data)\n",
    "    new_dev = vectorizer.transform(dev_data)\n",
    "    \n",
    "    #create LR model, fit, predict, and calculate F1 score\n",
    "    lr = LogisticRegression(C=100, solver=\"liblinear\", multi_class=\"auto\")\n",
    "    lr.fit(new_train, train_labels)\n",
    "    lr_pred = lr.predict(new_dev)\n",
    "    lr_f1 = metrics.f1_score(dev_labels, lr_pred, average = \"weighted\")\n",
    "    print(\"F1 Score for Logistic Regression Model using Tfidf Vectorizer: {:.4f}\".format(lr_f1))\n",
    "    \n",
    "    #pull in the probabilities from the model\n",
    "    probs=lr.predict_proba(new_dev)\n",
    "    \n",
    "    #calculate r ratios\n",
    "    #create empty list to store values\n",
    "    r_ratios = []\n",
    "    #loop through whole dev_data\n",
    "    for i in range(len(dev_labels)):\n",
    "        # r ratio = maximum predicted probability / predicted probability of the correct label \n",
    "        r_ratio = max(probs[i]) / probs[i,dev_labels[i]]\n",
    "        r_ratios.append(r_ratio)\n",
    "    r_ratios = np.array(r_ratios)\n",
    "    \n",
    "    #sort the r ratios using arg sort\n",
    "    ratios_sort = np.argsort(r_ratios)\n",
    "    #because these are sorted in ascending order and we want the highest 3, take the last 3 of the list\n",
    "    top_3 = ratios_sort[-3:]\n",
    "    \n",
    "    #print the predicted label, true label, r-ratio, and document content\n",
    "    for j in top_3:\n",
    "        print(\"R ratio: {:.4f}\".format(r_ratios[j]))\n",
    "        print(\"Predicted Label: {}\".format(newsgroups_train.target_names[lr_pred[j]]))\n",
    "        print(\"True Label: {}\".format(newsgroups_train.target_names[dev_labels[j]]))\n",
    "        print(\"Document: {} \\n\".format(dev_data[j]))\n",
    "    ### STUDENT END ###\n",
    "\n",
    "Q7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7SnJ7mTTyhe"
   },
   "source": [
    "The Tfidf vectorizer assigns a weight to each work which signifies its importance for a document that belongs in a corpus.  The weight a word is assigned increases proportionally to the number of times the word appears in the document. It's also offset by the number of documents in the corpus that contain the word to adjust for words that appear more frequently in general. In contrast, the CountVectorizer just returns a vector of integers corresponding to the number of times a word is used in a document. In terms of performance, the model that used the Tfidf vectorizer produced a higher accuracy (f1_score = .76) than the model using the count vectorizer (f1_score = .62). \n",
    "\n",
    "The r-ratio basically represents how *off* our prediction was based on the probabilities that we associated to each label. The higher the r-ratio, the farther off we were. Computer graphics and religion were mistaken mostly in these 3 examples because users would use terms like 'internet'. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "firstname_lastname_project3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
